{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import mcubes\n",
    "import os\n",
    "import trimesh\n",
    "\n",
    "from models.rendering import *\n",
    "from models.nerf import *\n",
    "from torchsummary import summary\n",
    "from datasets import dataset_dict\n",
    "from utils import load_ckpt, extract_model_state_dict, load_ckpt_other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cameras 5 {'id': 1, 'model': 'SIMPLE_RADIAL', 'width': 479, 'height': 358, 'params': [278.12527177107853, 239.5, 17.0, -0.13445126237284866]}\n",
      "<datasets.llff.LLFFDataset object at 0x7f79fb2484d0> yoooooooooooooo\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "{}\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "huh2\n",
      "huh3\n",
      "Found ckpts ['../DSNeRF/logs/release/250_frames_tensorboard_most_depth/299000.tar', '../DSNeRF/logs/release/250_frames_tensorboard_most_depth/300000.tar']\n",
      "Reloading from ../DSNeRF/logs/release/250_frames_tensorboard_most_depth/300000.tar\n",
      "NeRF(\n",
      "  (pts_linears): ModuleList(\n",
      "    (0): Linear(in_features=63, out_features=256, bias=True)\n",
      "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (5): Linear(in_features=319, out_features=256, bias=True)\n",
      "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (7): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (views_linears): ModuleList(\n",
      "    (0): Linear(in_features=283, out_features=128, bias=True)\n",
      "  )\n",
      "  (feature_linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (alpha_linear): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (rgb_linear): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n",
      "NeRF(\n",
      "  (pts_linears): ModuleList(\n",
      "    (0): Linear(in_features=63, out_features=256, bias=True)\n",
      "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (5): Linear(in_features=319, out_features=256, bias=True)\n",
      "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (7): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (views_linears): ModuleList(\n",
      "    (0): Linear(in_features=283, out_features=128, bias=True)\n",
      "  )\n",
      "  (feature_linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (alpha_linear): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (rgb_linear): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n",
      "NeRF(\n",
      "  (xyz_encoding_1): Sequential(\n",
      "    (0): Linear(in_features=63, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (xyz_encoding_2): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (xyz_encoding_3): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (xyz_encoding_4): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (xyz_encoding_5): Sequential(\n",
      "    (0): Linear(in_features=319, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (xyz_encoding_6): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (xyz_encoding_7): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (xyz_encoding_8): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (xyz_encoding_final): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (dir_encoding): Sequential(\n",
      "    (0): Linear(in_features=283, out_features=128, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (sigma): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (rgb): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=3, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Change here #\n",
    "img_wh = (480, 360) # full resolution of the input images\n",
    "dataset_name = 'llff' # blender or llff (own data)\n",
    "scene_name = '250_most_depth' # whatever you want\n",
    "root_dir = '/home/bowmonk/bladenerf//Hierarchical-Localization/outputs/larger_reconstruction/larger_reconstruction_250/' # the folder containing data\n",
    "ckpt_path = '/home/bowmonk/bladenerf/nerf_pl/ckpts/large_80/epoch=29.ckpt' # the model path\n",
    "load_path ='/home/bowmonk/bladenerf/DSNeRF/logs/release/250_frames_tensorboard_most_depth/300000.tar'\n",
    "###############\n",
    "\n",
    "kwargs = {'root_dir': root_dir,\n",
    "          'img_wh': img_wh}\n",
    "if dataset_name == 'llff':\n",
    "    kwargs['spheric_poses'] = True\n",
    "    kwargs['split'] = 'test'\n",
    "else:\n",
    "    kwargs['split'] = 'train'\n",
    "    \n",
    "chunk = 1024*16\n",
    "dataset = dataset_dict[dataset_name](**kwargs)\n",
    "\n",
    "embedding_xyz = Embedding(10)\n",
    "embedding_dir = Embedding(4)\n",
    "\n",
    "nerf_fine = NeRF()\n",
    "nerf_fine_other = NeRF(in_channels_xyz=63, in_channels_dir=27)\n",
    "load_ckpt(nerf_fine, ckpt_path, model_name='nerf_fine')\n",
    "checkpoint = extract_model_state_dict(load_path, model_name='nerf_fine')\n",
    "# load_ckpt(nerf_fine_other, ckpt_path, model_name='nerf_fine')\n",
    "\n",
    "nerf, nerf_fine = load_ckpt_other()\n",
    "\n",
    "nerf_fine.cuda().eval();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for tight bounds of the object (trial and error!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Te these parameters until the whole object lies tightly in range with little noise ###\n",
    "N = 512 # controls the resolution, set this number small here because we're only finding\n",
    "        # good ranges here, not yet for mesh reconstruction; we can set this number high\n",
    "        # when it comes to final reconstruction.\n",
    "xmin, xmax = -12, 12 # left/right range\n",
    "ymin, ymax = -12, 12 # forward/backward range\n",
    "zmin, zmax = -12, 12 # up/down range\n",
    "## Attention! the ranges MUST have the same length!\n",
    "sigma_threshold = 10. # controls the noise (lower=maybe more noise; higher=some mesh might be missing)\n",
    "############################################################################################\n",
    "\n",
    "x = np.linspace(xmin, xmax, N)\n",
    "y = np.linspace(ymin, ymax, N)\n",
    "z = np.linspace(zmin, zmax, N)\n",
    "\n",
    "xyz_ = torch.FloatTensor(np.stack(np.meshgrid(x, y, z), -1).reshape(-1, 3)).cuda()\n",
    "dir_ = torch.zeros_like(xyz_).cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    B = xyz_.shape[0]\n",
    "    out_chunks = []\n",
    "    other_out_chunks = []\n",
    "    for i in range(0, B, chunk):\n",
    "        xyz_embedded = embedding_xyz(xyz_[i:i+chunk]) # (N, embed_xyz_channels)\n",
    "        dir_embedded = embedding_dir(dir_[i:i+chunk]) # (N, embed_dir_channels)\n",
    "        xyzdir_embedded = torch.cat([xyz_embedded, dir_embedded], 1)\n",
    "        out_chunks += [nerf_fine(xyzdir_embedded)]\n",
    "    rgbsigma = torch.cat(out_chunks, 0)\n",
    "\n",
    "    \n",
    "sigma = rgbsigma[:, -1].cpu().numpy()\n",
    "sigma = np.maximum(sigma, 0)\n",
    "sigma = sigma.reshape(N, N, N)\n",
    "\n",
    "# The below lines are for visualization, COMMENT OUT once you find the best range and increase N!\n",
    "# vertices, triangles = mcubes.marching_cubes(sigma, sigma_threshold)\n",
    "# mesh = trimesh.Trimesh(vertices/N, triangles)\n",
    "# mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bowmonk/anaconda3/envs/nerf_pl/lib/python3.7/site-packages/collada/geometry.py:232: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
      "  if src.xmlnode not in meshnode.getchildren():\n",
      "/home/bowmonk/anaconda3/envs/nerf_pl/lib/python3.7/site-packages/collada/geometry.py:294: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
      "  if prim.xmlnode not in meshnode.getchildren():\n",
      "/home/bowmonk/anaconda3/envs/nerf_pl/lib/python3.7/site-packages/collada/geometry.py:299: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
      "  for child in meshnode.getchildren():\n"
     ]
    }
   ],
   "source": [
    "# # You can already export \"colorless\" mesh if you don't need color\n",
    "mcubes.export_mesh(vertices, triangles, f\"{scene_name}.dae\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate .vol file for volume rendering in Unity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99999994 1.         0.99999964 ... 0.         0.         0.        ]\n",
      "tensor([[ 3.5015e-04,  3.7227e-04,  5.3494e-04,  3.5870e+02],\n",
      "        [ 1.8565e-04,  1.9926e-04,  2.9594e-04,  3.7942e+02],\n",
      "        [ 1.0354e-04,  1.0992e-04,  1.6602e-04,  3.1742e+02],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -2.0457e+03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -2.0559e+03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -2.0688e+03]], device='cuda:0')\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " ...\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "assert N==512, \\\n",
    "    'Please set N to 512 in the two above cell! Remember to comment out the visualization code (last 3 lines)!'\n",
    "\n",
    "\n",
    "a = 1-np.exp(-(xmax-xmin)/N*sigma)\n",
    "a = a.flatten()\n",
    "\n",
    "rgb = (rgbsigma[:, :3].cpu().numpy()*255).astype(np.uint32)\n",
    "\n",
    "i = np.where(a>0)[0] # valid indices (alpha>0)\n",
    "\n",
    "rgb = rgb[i]\n",
    "a = a[i]\n",
    "s = rgb.dot(np.array([1<<24, 1<<16, 1<<8])) + (a*255).astype(np.uint32)\n",
    "res = np.stack([i, s], -1).astype(np.uint32).flatten()\n",
    "with open(f'{scene_name}.vol', 'wb') as f:\n",
    "    f.write(res.tobytes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract colored mesh\n",
    "\n",
    "Once you find the best range, now **RESTART** the notebook, and copy the configs to the following cell\n",
    "and execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cameras 5 {'id': 1, 'model': 'SIMPLE_RADIAL', 'width': 479, 'height': 358, 'params': [278.12527177107853, 239.5, 17.0, -0.13445126237284866]}\n",
      "<datasets.llff.LLFFDataset object at 0x7fd0af4e70d0> yoooooooooooooo\n",
      "Found ckpts ['../DSNeRF/logs/release/250_frames_tensorboard_most_depth/299000.tar', '../DSNeRF/logs/release/250_frames_tensorboard_most_depth/300000.tar']\n",
      "Reloading from ../DSNeRF/logs/release/250_frames_tensorboard_most_depth/300000.tar\n",
      "Predicting occupancy ...\n",
      "100%|███████████████████████████████████████████| 64/64 [00:00<00:00, 76.93it/s]\n",
      "Extracting mesh ...\n",
      "Removing noise ...\n",
      "Mesh has 0.35 M vertices and 0.72 M faces.\n",
      "True\n",
      "Found ckpts ['../DSNeRF/logs/release/250_frames_tensorboard_most_depth/299000.tar', '../DSNeRF/logs/release/250_frames_tensorboard_most_depth/300000.tar']\n",
      "Reloading from ../DSNeRF/logs/release/250_frames_tensorboard_most_depth/300000.tar\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Copy the variables you have above here! ####\n",
    "img_wh = (480, 360) # full resolution of the input images\n",
    "dataset_name = 'llff' # blender or llff (own data)\n",
    "scene_name = '250_frames_tensorboard_no_depth' # whatever you want\n",
    "root_dir = '/home/bowmonk/bladenerf//Hierarchical-Localization/outputs/larger_reconstruction/larger_reconstruction_250/' # the folder containing data\n",
    "ckpt_path = '/home/bowmonk/bladenerf/nerf_pl/ckpts/large_80/epoch=29.ckpt' # the model path\n",
    "load_path ='/home/bowmonk/bladenerf/DSNeRF/logs/release/250_frames_tensorboard_no_depth/300000.tar'\n",
    "###############\n",
    "N = 512 # controls the resolution, set this number small here because we're only finding\n",
    "        # good ranges here, not yet for mesh reconstruction; we can set this number high\n",
    "        # when it comes to final reconstruction.\n",
    "xmin, xmax = -13, 13 # left/right range\n",
    "ymin, ymax = -13, 13 # forward/backward range\n",
    "zmin, zmax = -13, 13 # up/down range\n",
    "## Attention! the ranges MUST have the same length!\n",
    "sigma_threshold = 5. # controls the noise (lower=maybe more noise; higher=some mesh might be missing)\n",
    "## Attention! the ranges MUST have the same length!\n",
    "# sigma_threshold = 10. # controls the noise (lower=maybe more noise; higher=some mesh might be missing)\n",
    "###############################################\n",
    "\n",
    "import os\n",
    "os.environ['ROOT_DIR'] = root_dir\n",
    "os.environ['DATASET_NAME'] = dataset_name\n",
    "os.environ['SCENE_NAME'] = scene_name\n",
    "os.environ['IMG_SIZE'] = f\"{img_wh[0]} {img_wh[1]}\"\n",
    "os.environ['CKPT_PATH'] = ckpt_path\n",
    "os.environ['N_GRID'] = \"128\" # final resolution. You can set this number high to preserve more details\n",
    "os.environ['X_RANGE'] = f\"{xmin} {xmax}\"\n",
    "os.environ['Y_RANGE'] = f\"{ymin} {ymax}\"\n",
    "os.environ['Z_RANGE'] = f\"{zmin} {zmax}\"\n",
    "os.environ['SIGMA_THRESHOLD'] = str(sigma_threshold)\n",
    "os.environ['OCC_THRESHOLD'] = \"0.1\" # probably doesn't require tuning. If you find the color is not close\n",
    "                                    # to real, try to set this number smaller (the effect of this number\n",
    "                                    # is explained in my youtube video)\n",
    "os.environ['USE_VERTEX_NORMAL'] = 'True'\n",
    "!python extract_color_mesh.py \\\n",
    "    --root_dir $ROOT_DIR \\\n",
    "    --dataset_name $DATASET_NAME \\\n",
    "    --scene_name $SCENE_NAME \\\n",
    "    --img_wh $IMG_SIZE \\\n",
    "    --ckpt_path $CKPT_PATH \\\n",
    "    --N_grid $N_GRID \\\n",
    "    --x_range $X_RANGE \\\n",
    "    --y_range $Y_RANGE \\\n",
    "    --z_range $Z_RANGE \\\n",
    "    --sigma_threshold $SIGMA_THRESHOLD \\\n",
    "    --occ_threshold $OCC_THRESHOLD \\\n",
    "    --use_vertex_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
